{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 101: Building Your First Agent\n",
    "\n",
    "Welcome to LangGraph 101! This notebook will walk you through the core concepts of building agents with LangChain and LangGraph.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to interact with language models\n",
    "- Working with messages and conversation\n",
    "- Adding tools to extend LLM capabilities\n",
    "- Building an agent that can reason and act\n",
    "- Adding memory to maintain context\n",
    "- Streaming responses for better UX\n",
    "<br> \n",
    "<br> \n",
    "---\n",
    "<br> \n",
    "\n",
    "> **Note:** This tutorial uses LangChain v1 (alpha), which provides the easiest way to start building with LLMs. LangChain agents are built on top of LangGraph, providing durable execution, streaming, human-in-the-loop, and persistence out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup & Installation\n",
    "\n",
    "First, let's install the necessary packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install --pre -U langchain langchain-anthropic langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "# We'll use OpenAI in this tutorial, but you can swap to any provider!\n",
    "# Supported providers: OpenAI, Anthropic, Google, Cohere, and many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Your First LLM Call\n",
    "\n",
    "LangChain provides a **standard model interface** that works across all providers. This means you can easily swap between OpenAI, Anthropic, Google, and other providers without changing your code.\n",
    "\n",
    "Let's start by initializing a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain is an open-source framework for building AI-powered applications that use large language models (LLMs). It doesn’t provide a model itself; instead it offers tools to structure and manage how you interact with LLMs and external data or actions.\n",
      "\n",
      "Key ideas:\n",
      "- Chains: compose a sequence of steps (prompts, LLM calls, data processing) so outputs feed into the next step.\n",
      "- Prompts and templates: reusable prompt formats with variables.\n",
      "- Memory: keep context across interactions (e.g., conversation history).\n",
      "- Tools and agents: let the model decide to call external tools (search, code execution, databases, calculators, etc.) to perform tasks.\n",
      "- Retrieval and data sources: connect to vector stores and document loaders to build retrieval-augmented generation (RAG) systems.\n",
      "- Integrations: supports multiple backends (OpenAI, Cohere, HuggingFace, etc.) and, in addition to Python, has a JavaScript/TypeScript version.\n",
      "\n",
      "Common use cases:\n",
      "- Chatbots that reference a knowledge base\n",
      "- Question-answering with document retrieval\n",
      "- Code assistants or data analysis that run external tools\n",
      "- Automated workflows that require multi-step reasoning\n",
      "\n",
      "Getting started (high level):\n",
      "- Install (Python): pip install langchain (or npm install langchain for JS/TS)\n",
      "- Create a simple chain that prompts an LLM for a response\n",
      "- Extend with memory, tools, or vector stores as needed\n",
      "\n",
      "Example snippet (Python, simplified):\n",
      "- from langchain import LLMChain, PromptTemplate\n",
      "- template = \"You are a helpful assistant. Question: {question}\"\n",
      "- prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
      "- chain = LLMChain(llm=your_llm_instance, prompt=prompt)\n",
      "- print(chain.run({\"question\": \"What is LangChain?\"}))\n",
      "\n",
      "If you’d like, tell me your use case and preferred language (Python or JavaScript), and I can give you a concrete, minimal example.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Initialize a chat model - you can easily swap providers!\n",
    "# Examples: \"openai:gpt-5-nano\", \"anthropic:claude-3-7-sonnet-latest\", \"google:gemini-2.0-flash\"\n",
    "model = init_chat_model(\"openai:gpt-5-nano\")\n",
    "\n",
    "# Make your first call!\n",
    "response = model.invoke(\"What is LangChain?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `init_chat_model()` gives you a standardized interface to any LLM provider\n",
    "- `.invoke()` sends a message and returns a response\n",
    "- No provider lock-in - swap models easily!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Messages\n",
    "\n",
    "**Messages** are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both content and metadata.\n",
    "\n",
    "There are different message types:\n",
    "- **SystemMessage** - Instructions for how the model should behave\n",
    "- **HumanMessage** - User input\n",
    "- **AIMessage** - Model responses\n",
    "- **ToolMessage** - Results from tool executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "An agent is anything that can perceive its surroundings and take actions to affect them. In AI terms:\n",
      "\n",
      "- Perceives: It has sensors to see or measure the environment.\n",
      "- Acts: It has actuators or a way to act on the environment.\n",
      "- Goal-directed: It acts to achieve some objective or maximize a performance measure.\n",
      "\n",
      "In more formal AI language:\n",
      "- An agent has an agent function that maps its history of perceptions to actions.\n",
      "- A rational (or goal/utility-based) agent tries to choose actions that maximize expected performance given what it knows.\n",
      "\n",
      "Common types:\n",
      "- Reactive agents: respond directly to current percepts (no internal model).\n",
      "- Model-based agents: keep an internal state/model of the world.\n",
      "- Goal-based agents: choose actions to achieve specific goals.\n",
      "- Utility-based agents: choose actions to maximize a utility (a measure of “happiness” or satisfaction).\n",
      "- Learning agents: improve their behavior over time based on experience.\n",
      "\n",
      " everyday examples:\n",
      "- A thermostat: senses temperature, turns heater on/off to reach a desired temperature.\n",
      "- A vacuum cleaning robot: senses dirt, obstacles, and battery level, then moves and cleans accordingly.\n",
      "- A spam filter: perceives email features and decides to classify it as spam or not (an agent acting in a software environment).\n",
      "\n",
      "If you want, tell me the context (AI course, software project, etc.), and I can tailor the explanation or give a worked example.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Create a conversation with different message types\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful AI assistant that explains technical concepts simply.\"),\n",
    "    HumanMessage(content=\"What is an agent?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-turn Conversations\n",
    "\n",
    "Messages make it easy to maintain conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here’s a simple, concrete example of an agent: a tiny vacuum-cleaning robot in a grid world.\n",
      "\n",
      "- Environment\n",
      "  - A 3x3 grid of rooms. Some cells may contain dirt, some may be blocked by obstacles.\n",
      "  - A charging dock is at the starting cell.\n",
      "  - Goal: clean all dirt and manage battery so the robot can recharge when needed.\n",
      "\n",
      "- Percepts (what the agent can sense)\n",
      "  - Its current cell: is there dirt here or not?\n",
      "  - Battery level (rough idea of how much energy remaining).\n",
      "\n",
      "- Actions the agent can take\n",
      "  - Move North, South, East, or West (to an adjacent cell, if not blocked).\n",
      "  - Suck (clean dirt in the current cell).\n",
      "  - Charge (go to the charging dock and recharge).\n",
      "\n",
      "- Agent function (a simple policy)\n",
      "  - If the current cell has dirt, Suck.\n",
      "  - Else if battery is low (below a threshold, e.g., 20%), move toward the charging dock to recharge.\n",
      "  - Else move toward the nearest dirty cell (using Manhattan distance to decide the target).\n",
      "  - If movement is blocked by an obstacle, pick another direction that makes progress toward the target.\n",
      "\n",
      "- Worked example (small run)\n",
      "  - Setup:\n",
      "    - Grid cells: (row, column) from (1,1) at top-left to (3,3) at bottom-right.\n",
      "    - Dirt at (3,3). Obstacle at (2,2). Dock at (1,1).\n",
      "    - Start at (1,1) with battery 50.\n",
      "  - Step 1:\n",
      "    - Percept: no dirt here, battery 50.\n",
      "    - Action: move East to (1,2).\n",
      "  - Step 2:\n",
      "    - Percept: no dirt here, battery 49.\n",
      "    - Action: move East to (1,3).\n",
      "  - Step 3:\n",
      "    - Percept: no dirt here, battery 48.\n",
      "    - Action: move South to (2,3).\n",
      "  - Step 4:\n",
      "    - Percept: no dirt here, battery 47.\n",
      "    - Action: move South to (3,3).\n",
      "  - Step 5:\n",
      "    - Percept: dirt present here, battery 46.\n",
      "    - Action: Suck (clean the dirt).\n",
      "  - Step 6:\n",
      "    - Percept: now clean here, battery 46.\n",
      "    - If there were more dirt, it would move toward the next one; otherwise it might return to dock to recharge if the battery gets low.\n",
      "  - Note: This is a very small, hand-wired example. In real systems the path planning, obstacle handling, and charging behavior can be more sophisticated.\n",
      "\n",
      "Key idea\n",
      "- An agent is defined by how it perceives the world, what actions it can take, and the policy it uses to choose actions to achieve its goal. In this toy robot, the policy is a simple if-else rule that handles cleaning first, battery management second, and navigation toward dirt third.\n",
      "\n",
      "If you want, I can tailor this to a different context (e.g., a software assistant, a game NPC, or a classroom project) and walk through a different example. What context are you thinking of?\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "messages.append(response)  # Add AI response to history\n",
    "messages.append(HumanMessage(content=\"Can you give me an example?\"))\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Messages represent the conversation history\n",
    "- SystemMessage sets the model's behavior\n",
    "- Build multi-turn conversations by appending messages to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Adding Tools - Extending LLM Capabilities\n",
    "\n",
    "LLMs are great at language, but they can't access external data or perform actions. **Tools** extend their capabilities. You can give an LLM a list of tools, and when it needs one, it will specify which tool to call. Your job is to execute the tool and feed the results back to the LLM so it can decide what to do next.\n",
    "\n",
    "You can create a tool just by writing a Python function with a clear description. LangChain's `@tool` decorator handles formatting the function's information in the LLM's desired format.  \n",
    "\n",
    "Let's create some simple tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"temperature_fahrenheit\": 55.7, \"weather_code\": 3}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Basic hardcoded tool\n",
    "@tool\n",
    "def search_movies(genre: str) -> str:\n",
    "    \"\"\"Search for movies by genre.\"\"\"\n",
    "    # In a real app, this would query a movie database\n",
    "    movies = {\n",
    "        \"sci-fi\": \"Dune, Interstellar, Blade Runner 2049\",\n",
    "        \"comedy\": \"The Grand Budapest Hotel, Superbad, Knives Out\",\n",
    "        \"action\": \"Mad Max: Fury Road, John Wick, Mission Impossible\"\n",
    "    }\n",
    "    return movies.get(genre.lower(), \"No movies found for that genre\")\n",
    "\n",
    "# More realistic tool that calls an API\n",
    "@tool\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get current temperature in Fahrenheit and weather code for given coordinates.\n",
    "\n",
    "    Args:\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "\n",
    "    Returns:\n",
    "        JSON string with temperature_fahrenheit and weather_code (do not include the code in your response, translate it to plain English)\n",
    "    \"\"\"\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"current\": \"temperature_2m,weather_code\",\n",
    "        \"temperature_unit\": \"fahrenheit\"\n",
    "    }\n",
    "\n",
    "    weather = requests.get(url, params=params).json()[\"current\"]\n",
    "    temperature = weather[\"temperature_2m\"]\n",
    "    weather_code = weather[\"weather_code\"]\n",
    "    result = {\n",
    "        \"temperature_fahrenheit\": temperature,\n",
    "        \"weather_code\": weather_code\n",
    "    }\n",
    "\n",
    "    return json.dumps(result)\n",
    "\n",
    "\n",
    "\n",
    "# Test a tool directly with SF's coordinates\n",
    "print(get_weather.invoke({\"latitude\": 37.77, \"longitude\": 122.42}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling (Function Calling)\n",
    "\n",
    "Now let's give these tools to the model using `.bind_tools()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls: [{'name': 'get_weather', 'args': {'latitude': 47.6062, 'longitude': -122.3321}, 'id': 'call_aAO06SD8SrIu0FWPW33sVZyL', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# Bind tools to the model\n",
    "tools = [get_weather, search_movies]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "message = \"What's the weather like in Seattle?\"\n",
    "\n",
    "# The model can now decide to call tools\n",
    "response = model_with_tools.invoke(message)\n",
    "\n",
    "# Check if the model wants to call a tool\n",
    "print(\"Tool calls:\", response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model returns a **tool call** request with:\n",
    "- `name`: Which tool to call\n",
    "- `args`: Arguments to pass to the tool\n",
    "- `id`: Unique identifier for tracking\n",
    "\n",
    "Let's execute the tool and continue the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Right now in Seattle, it’s about 59°F with cloudy skies. Want an hourly forecast or precipitation chances for the day?\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# Execute the tool call\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "    \n",
    "    # Call the actual tool\n",
    "    if tool_call[\"name\"] == \"get_weather\":\n",
    "        result = get_weather.invoke(tool_call[\"args\"])\n",
    "\n",
    "    elif tool_call[\"name\"] == \"search_movies\":\n",
    "        result = search_movies.invoke(tool_call[\"args\"])\n",
    "    \n",
    "    # Create a ToolMessage with the result\n",
    "    tool_message = ToolMessage(\n",
    "        content=result,\n",
    "        tool_call_id=tool_call[\"id\"]\n",
    "    )\n",
    "    \n",
    "    # Continue the conversation with the tool result\n",
    "    final_response = model_with_tools.invoke([\n",
    "        HumanMessage(content=message),\n",
    "        response,\n",
    "        tool_message\n",
    "    ])\n",
    "    \n",
    "    final_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Tools are Python functions decorated with `@tool`\n",
    "- Good descriptions help the model know when to use each tool\n",
    "- Tool calling flow: Model requests tool → Execute tool → Return result → Model synthesizes final response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Building Your First Agent with `create_agent()`\n",
    "\n",
    "Manually defining a specific sequence of LLM calls and tool calls is tedious and inflexible. Instead, we can use an **agent** that runs this loop:\n",
    "1. Model decides which tool to call (if any)\n",
    "2. Tool gets executed\n",
    "3. Result goes back to model\n",
    "4. Repeat until task is complete\n",
    "\n",
    "LangChain makes this easy with `create_agent()` - **build an agent in ~10 lines of code!**\n",
    "The prebuilt agent handles running the loop described above - you just specify the system prompt and tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather in NYC? Also recommend some sci-fi movies.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_0eox49rKxFR4UAXKntF9M8zK)\n",
      " Call ID: call_0eox49rKxFR4UAXKntF9M8zK\n",
      "  Args:\n",
      "    latitude: 40.7128\n",
      "    longitude: -74.006\n",
      "  search_movies (call_eSgJrB0rnejaQZScAjdk1Aag)\n",
      " Call ID: call_eSgJrB0rnejaQZScAjdk1Aag\n",
      "  Args:\n",
      "    genre: sci-fi\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "{\"temperature_fahrenheit\": 53.1, \"weather_code\": 0}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_movies\n",
      "\n",
      "Dune, Interstellar, Blade Runner 2049\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- NYC weather: About 53.1°F with clear skies.\n",
      "\n",
      "- Sci-fi movie recommendations: Dune, Interstellar, Blade Runner 2049.\n",
      "\n",
      "Want more options or streaming availability for these?\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create an agent with tools\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_weather, search_movies],\n",
    "    system_prompt=\"You are a helpful assistant that can check weather and recommend movies.\"\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather in NYC? Also recommend some sci-fi movies.\")]\n",
    "})\n",
    "\n",
    "# Print the final response\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The agent automatically:\n",
    "1. Analyzed the user's request\n",
    "2. Called `get_weather(\"NYC\")`\n",
    "3. Called `search_movies(\"sci-fi\")`\n",
    "4. Synthesized the results into a natural response\n",
    "\n",
    "Let's visualize the agent's structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x10f030ec0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `create_agent()` builds a complete agent in ~10 lines\n",
    "- The agent automatically handles the reasoning → action → observation loop\n",
    "- Built on LangGraph for production features (persistence, streaming, human-in-the-loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding Memory & State\n",
    "\n",
    "Right now, each agent invocation is independent. Let's add **memory** so the agent can maintain context across multiple interactions.\n",
    "\n",
    "LangGraph uses **checkpointers** to save and restore state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Nice to meet you, Alice! Since you love sci-fi movies, would you like me to recommend some for you?\n",
      "\n",
      "Response 2: Your name is Alice and you love sci-fi movies. Would you like some recommendations for sci-fi movies?\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import uuid\n",
    "\n",
    "# Create a checkpointer for memory\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Create an agent with memory\n",
    "agent_with_memory = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[get_weather, search_movies],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Create a thread for this conversation\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# First interaction\n",
    "result1 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is Alice and I love sci-fi movies.\"}]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Response 1:\", result1[\"messages\"][-1].content)\n",
    "\n",
    "# Second interaction - the agent remembers!\n",
    "result2 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name and what movies do I like?\"}]},\n",
    "    config=config\n",
    ")\n",
    "print(\"\\nResponse 2:\", result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding State & Threads\n",
    "\n",
    "- **State**: The agent's \"memory\" - includes message history and any custom data\n",
    "- **Thread**: A conversation session identified by `thread_id`\n",
    "- **Checkpointer**: Saves state after each step, enabling memory and error recovery\n",
    "\n",
    "Each thread is independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New thread response: I'm sorry, but I don't know your name. Can you please tell me?\n"
     ]
    }
   ],
   "source": [
    "# New thread - agent won't remember Alice\n",
    "new_thread_id = str(uuid.uuid4())\n",
    "new_config = {\"configurable\": {\"thread_id\": new_thread_id}}\n",
    "\n",
    "result3 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    config=new_config\n",
    ")\n",
    "print(\"New thread response:\", result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Checkpointers enable memory across interactions\n",
    "- Thread IDs separate different conversations\n",
    "- State persists automatically - no manual state management needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Streaming for Better UX\n",
    "\n",
    "LLMs can take a while to respond. **Streaming** shows progress in real-time, dramatically improving user experience.\n",
    "\n",
    "LangChain supports multiple streaming modes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Agent Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming agent steps:\n",
      "\n",
      "Step: model\n",
      "   Tool call: get_weather\n",
      "\n",
      "Step: tools\n",
      "   Content: {\"temperature_fahrenheit\": 53.5, \"weather_code\": 0}\n",
      "\n",
      "Step: model\n",
      "   Content: Boston right now is about 53.5°F with clear skies. It’s a bit cool, so a light jacket is a good idea...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream agent progress with stream_mode=\"updates\"\n",
    "print(\"Streaming agent steps:\\n\")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, data in chunk.items():\n",
    "        print(f\"Step: {node_name}\")\n",
    "        if \"messages\" in data:\n",
    "            message = data[\"messages\"][-1]\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                print(f\"   Tool call: {message.tool_calls[0]['name']}\")\n",
    "            elif hasattr(message, 'content'):\n",
    "                print(f\"   Content: {message.content[:100]}...\" if len(message.content) > 100 else f\"   Content: {message.content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming LLM Tokens\n",
    "\n",
    "For a ChatGPT-like experience, stream tokens as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming tokens:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream tokens with stream_mode=\"messages\"\n",
    "print(\"Streaming tokens:\\n\")\n",
    "\n",
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about LangGraph in one sentence.\"}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    # Only print content from the agent node\n",
    "    if metadata.get('langgraph_node') == 'agent':\n",
    "        # Get text from content blocks\n",
    "        for block in token.content_blocks:\n",
    "            if block.get('type') == 'text' and block.get('text'):\n",
    "                print(block['text'], end='', flush=True)\n",
    "\n",
    "print(\"\\n\")  # New line at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `stream_mode=\"updates\"` - See each agent step (useful for debugging)\n",
    "- `stream_mode=\"messages\"` - Stream LLM tokens (ChatGPT-like UX)\n",
    "- Streaming is built-in - no extra setup required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Putting It All Together - A Practical Example\n",
    "\n",
    "Let's build a more realistic agent that combines everything we've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PERSONAL ASSISTANT DEMO\n",
      "==================================================\n",
      "\n",
      "User: Hi, I'm Alice. Can you check my preferences and recommend a movie?\n",
      "\n",
      "Assistant: Hi Alice! I’d be happy to check your saved preferences and suggest a movie.\n",
      "\n",
      "Could you share the user ID (or the email you use with this account) so I can pull your preferences? If you’d rather not share that, you can tell me a couple of genres you like (e.g., drama, sci-fi, comedy) and I’ll suggest something right away.\n",
      "\n",
      "User: Also, what's the weather like in San Francisco?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create more realistic tools\n",
    "@tool\n",
    "def get_user_preferences(user_id: str) -> str:\n",
    "    \"\"\"Get a user's saved preferences.\"\"\"\n",
    "    # Simulate a user database\n",
    "    preferences = {\n",
    "        \"alice\": \"Loves sci-fi movies, prefers warm weather destinations\",\n",
    "        \"bob\": \"Enjoys comedy films, likes cold climates for travel\"\n",
    "    }\n",
    "    return preferences.get(user_id.lower(), \"No preferences found\")\n",
    "\n",
    "@tool\n",
    "def book_recommendation(genre: str, user_preferences: str = \"\") -> str:\n",
    "    \"\"\"Get personalized movie recommendations based on genre and user preferences.\"\"\"\n",
    "    recommendations = {\n",
    "        \"sci-fi\": \"Based on your preferences, try: Arrival, Ex Machina, or The Martian\",\n",
    "        \"comedy\": \"Based on your preferences, try: The Big Lebowski, Anchorman, or Bridesmaids\"\n",
    "    }\n",
    "    return recommendations.get(genre.lower(), \"No recommendations available\")\n",
    "\n",
    "# Create a helpful assistant agent\n",
    "assistant = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_weather, get_user_preferences, book_recommendation],\n",
    "    system_prompt=\"\"\"You are a helpful personal assistant. \n",
    "    \n",
    "    You can:\n",
    "    - Check weather for any city\n",
    "    - Look up user preferences\n",
    "    - Recommend movies based on preferences\n",
    "    \n",
    "    Always be friendly and personalize your responses based on user preferences.\"\"\",\n",
    "    checkpointer=MemorySaver()\n",
    ")\n",
    "\n",
    "# Demo conversation\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PERSONAL ASSISTANT DEMO\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Interaction 1\n",
    "print(\"User: Hi, I'm Alice. Can you check my preferences and recommend a movie?\\n\")\n",
    "result = assistant.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, I'm Alice. Can you check my preferences and recommend a movie?\"}]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Assistant: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "# Interaction 2\n",
    "print(\"User: Also, what's the weather like in San Francisco?\\n\")\n",
    "result = assistant.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Also, what's the weather like in San Francisco?\"}]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Assistant: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Next Steps - Exploring LangGraph Primitives\n",
    "\n",
    "We've been using `create_agent()`, which is built on **LangGraph**. LangGraph gives you full control over agent behavior using three core primitives:\n",
    "\n",
    "### Core LangGraph Concepts:\n",
    "\n",
    "1. **State** \n",
    "   - Shared data structure passed between nodes\n",
    "   - Represents the agent's \"memory\"\n",
    "   - Can include messages, custom data, etc.\n",
    "\n",
    "2. **Nodes** \n",
    "   - Python functions that process state\n",
    "   - Each node performs a specific task\n",
    "   - Examples: call LLM, execute tool, validate input\n",
    "\n",
    "3. **Edges** \n",
    "   - Define flow between nodes\n",
    "   - Can be normal (always go to next node)\n",
    "   - Or conditional (decide based on logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use `create_agent()` vs custom LangGraph?\n",
    "\n",
    "**Use `create_agent()` when:**\n",
    "- Building standard ReAct-style agents\n",
    "- You need quick prototyping\n",
    "- Default behavior works for your use case\n",
    "\n",
    "**Use custom LangGraph when:**\n",
    "- You need custom control flow (e.g., approval workflows)\n",
    "- Building multi-agent systems\n",
    "- Implementing human-in-the-loop patterns\n",
    "- Complex state management requirements\n",
    "\n",
    "For more advanced patterns, check out:\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangChain Academy](https://academy.langchain.com/)\n",
    "- The `multi_agent.ipynb` notebook in this repo (LangGraph 201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a ReAct Agent from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore how LangGraph's primitives work, let's rebuild the agent we created above, but without `create_agent()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chatbot is simple - just an LLM with some associated tools - so all we need to keep in our state is a list of human messages, AI messages, and tool messages that grows as the conversation goes on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Contains the full conversation history as it grows during the conversation\n",
    "    messages: Annotated[List[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "We can reuse the tools we defined above. However, we need to create a node that handles tool calls and formats the results as `ToolMessage` objects for the LLM to work with. Instead of defining the node ourselves, we'll use LangGraph's prebuild `ToolNode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "# Node\n",
    "tools = [search_movies, get_weather]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our node for the main assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "def assistant(state: State, config: RunnableConfig):\n",
    "    # Create a list of messages to send to the LLM, beginning with our fixed system prompt\n",
    "    system_prompt = \"You are a helpful assistant that can check weather and recommend movies.\"\n",
    "    all_messages = [SystemMessage(system_prompt)] + state[\"messages\"]\n",
    "    # Invoke the LLM\n",
    "    response = model_with_tools.invoke(all_messages)\n",
    "    # Update the state with the response from the LLM\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define a control flow that connects between our defined nodes, and that's where the concept of edges come in.\n",
    "\n",
    "**Edges are connections between nodes. They define the flow of the graph.**\n",
    "* **Normal edges** are deterministic and always go from one node to its defined target\n",
    "* **Conditional edges** are used to dynamically route between nodes, implemented as functions that return the next node to visit based upon some logic. \n",
    "\n",
    "In this case, we want a **conditional edge** from our subagent that determines whether to: \n",
    "- Invoke tools, or,\n",
    "- Route to the end if user query has been finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge that determines whether to continue or not\n",
    "def should_continue(state: State, config: RunnableConfig):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # The LLM wants to make tool calls, we should execute them and continue\n",
    "    if last_message.tool_calls:\n",
    "        return \"continue\"\n",
    "    # The LLM returned a response instead of tool calls, we're finished\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Graph!\n",
    "\n",
    "Now that we've defined our state, nodes, and conditional edge let's put it all together and construct our react agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Start by defining a builder with our State class\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes \n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "\n",
    "# Add edges \n",
    "# First, we define the start node. The query will always route to the assistant node first. \n",
    "builder.add_edge(START, \"assistant\")\n",
    "\n",
    "# Add in the conditional edge after we call the LLM\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # If `continue`, then we call the tool node.\n",
    "        \"continue\": \"tool_node\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Always return to the LLM after calling tools\n",
    "builder.add_edge(\"tool_node\", \"assistant\")\n",
    "\n",
    "agent = builder.compile(name=\"agent\")\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully rebuilt a ReAct agent from scratch identical to the basic one we made using `create_agent`. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = \"What is the weather in SF today, and what are some good Sci-Fi movies?\"\n",
    "\n",
    "result = agent.invoke({\"messages\": HumanMessage(content=question)})\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've learned the core concepts of building agents with LangChain and LangGraph:\n",
    "\n",
    " **Models** - Standardized interface across providers  \n",
    " **Messages** - Building block of conversations  \n",
    " **Tools** - Extending LLM capabilities  \n",
    " **Agents** - Automated reasoning and action loops  \n",
    " **Memory** - Maintaining context across interactions  \n",
    " **Streaming** - Real-time user experience  \n",
    " **LangGraph** - The foundation powering it all\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Build your own agent** with your specific tools and use case\n",
    "2. **Explore advanced patterns** in the `multi_agent.ipynb` notebook\n",
    "3. **Add debugging** with [LangSmith](https://smith.langchain.com)\n",
    "4. **Deploy to production** using LangGraph's persistence and error recovery\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/introduction/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangSmith for Debugging](https://smith.langchain.com)\n",
    "- [LangChain Academy](https://academy.langchain.com/)\n",
    "<br> \n",
    "<br> \n",
    "---\n",
    "<br> \n",
    "\n",
    "**Happy building!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
